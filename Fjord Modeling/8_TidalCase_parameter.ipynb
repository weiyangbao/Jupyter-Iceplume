{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61ffb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain parameters in Tidal Cases\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d877b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting flux at ice front\n",
    "def IFA(case_path, case_id):\n",
    "    # Grid areas    \n",
    "    Area = np.empty([90, 10])\n",
    "    Area[:20,:] = 400\n",
    "    Area[20:50,:] = 800\n",
    "    Area[50:,:] = 1200\n",
    "\n",
    "    file0 = xr.open_dataset(case_path + '/icefrntA_' + str(format(case_id,'03d')) + '.nc')\n",
    "    t0 = 89\n",
    "    #tn = 120\n",
    "    # removed duplicated data caused by model restart\n",
    "    file = file0.isel(T=~file0.get_index(\"T\").duplicated())\n",
    "    state = file.isel(Y=range(35,45), T=range(t0,len(file.T)))\n",
    "    \n",
    "    MR = state.icefrntA.isel(X=1).data.mean(0) # Melt rate at the icefront\n",
    "    Qsm = (MR*Area).sum()/(24*3600)\n",
    "    return Qsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water temperature at ice front\n",
    "def icefrntT(case_path, case_id):\n",
    "    File1 = xr.open_dataset(case_path + '/state_' + str(format(case_id,'03d')) + '.nc')\n",
    "    Grid = xr.open_dataset(case_path + '/grid_' + str(format(case_id,'03d')) + '.nc')  \n",
    "    State = File1.isel(T=~File1.get_index(\"T\").duplicated())\n",
    "    \n",
    "    # Confine to the range of fjord\n",
    "    state = State.isel(X=range(260), Xp1=range(261), Y=range(35,45), T=range(1,len(State.T)))\n",
    "    grid = Grid.isel(X=range(260), Xp1=range(261), Y=range(35,45))\n",
    "\n",
    "    U = (state.U.data[:,:,:,1:] + state.U.data[:,:,:,:-1]) / 2 # Along-channel velocity\n",
    "    \n",
    "    drF = np.broadcast_to(grid.drF.data[np.newaxis, :, np.newaxis, np.newaxis], U.shape)\n",
    "    dyF = np.broadcast_to(grid.dyF.data[np.newaxis, np.newaxis, :, :], U.shape)\n",
    "    HFacC = np.broadcast_to(grid.HFacC.data[np.newaxis, :, :, :], U.shape)\n",
    "    DA = drF * dyF * HFacC\n",
    "   \n",
    "    t0 = 89 # Starting time index\n",
    "    da = DA[t0:,:,:,1].mean(axis=(0,2))\n",
    "    Ti = state.Temp.data[t0:,:,:,1].mean(axis=(0,2))\n",
    "    Ui = U[t0:,:,:,1].mean(axis=(0,2))\n",
    "    \n",
    "    Tvi = np.sum(Ti*da) / np.sum(da)\n",
    "    return Tvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592815a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '/work/oceans/wbao/MITgcm_results/iceplume/6_Tide_minhs'\n",
    "path2 = '/work/oceans/wbao/MITgcm_results/iceplume/weak_Tide_minhs' # Qsg=250\n",
    "\n",
    "\n",
    "caseN1 = np.array([1,2,3,4,5])\n",
    "Qsm1 = np.empty(len(caseN1))\n",
    "Tice1 = np.empty(len(caseN1))\n",
    "\n",
    "caseN2 = np.array([1,2,3])\n",
    "Qsm2 = np.empty(len(caseN2))\n",
    "Tice2 = np.empty(len(caseN2))\n",
    "\n",
    "for i in range(len(caseN1)):\n",
    "    \n",
    "    Qsm1[i] = IFA(path1, caseN1[i])\n",
    "    Tice1[i] = icefrntT(path1, caseN1[i])\n",
    "\n",
    "    \n",
    "for j in range(len(caseN2)):\n",
    "    \n",
    "    Qsm2[j] = IFA(path2, caseN2[j])\n",
    "    Tice2[j] = icefrntT(path2, caseN2[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fe81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qsm2, Qsm1, Tice2, Tice1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07990bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = xr.open_dataset('/home/1959/Parameters/FjordModeling/Tide01.nc')\n",
    "file2 = xr.open_dataset('/home/1959/Parameters/FjordModeling/Tide02.nc')\n",
    "file3 = xr.open_dataset('/home/1959/Parameters/FjordModeling/Tide03.nc')\n",
    "\n",
    "a11 = np.concatenate([file1.alpha11.data, file2.alpha11.data, file3.alpha11.data])\n",
    "a22 = np.concatenate([file1.alpha22.data, file2.alpha22.data, file3.alpha22.data])\n",
    "\n",
    "Qin1 = np.concatenate([file1.Qin1.data, file2.Qin1.data, file3.Qin1.data])\n",
    "Qin1_adj = np.concatenate([file1.Qin1_adj.data, file2.Qin1_adj.data, file3.Qin1_adj.data])\n",
    "\n",
    "Qin2 = np.concatenate([file1.Qin2.data, file2.Qin2.data, file3.Qin2.data])\n",
    "Qin2_adj = np.concatenate([file1.Qin2_adj.data, file2.Qin2_adj.data, file3.Qin2_adj.data])\n",
    "\n",
    "Qout1 = np.concatenate([file1.Qout1.data, file2.Qout1.data, file3.Qout1.data])\n",
    "Qout1_adj = np.concatenate([file1.Qout1_adj.data, file2.Qout1_adj.data, file3.Qout1_adj.data])\n",
    "\n",
    "Qout2 = np.concatenate([file1.Qout2.data, file2.Qout2.data, file3.Qout2.data])\n",
    "Qout2_adj = np.concatenate([file1.Qout2_adj.data, file2.Qout2_adj.data, file3.Qout2_adj.data])\n",
    "\n",
    "Ts_in = np.concatenate([file1.Ts_in.data, file2.Ts_in.data, file3.Ts_in.data])\n",
    "Ts = np.concatenate([file1.Ts.data, file2.Ts.data, file3.Ts.data])\n",
    "Tf = np.concatenate([file1.Tf.data, file2.Tf.data, file3.Tf.data])\n",
    "\n",
    "Qsm = np.concatenate([file1.Qsm.data, file2.Qsm.data, file3.Qsm.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05a9f4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.714578  , 0.71510556, 0.71483592, 0.72686785, 0.74121893,\n",
       "        0.74971925, 0.76033412, 0.76944392, 0.80404705,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan]),\n",
       " array([0.04379473, 0.04338967, 0.04361214, 0.16954694, 0.27852152,\n",
       "        0.36469475, 0.42617604, 0.48368894, 0.67170154,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan]),\n",
       " array([0.70277548, 0.70344345, 0.70310735, 0.67694333, 0.65246778,\n",
       "        0.62301338, 0.60430422, 0.58125379, 0.46698783, 0.33123252,\n",
       "        0.17610844, 0.13322018, 0.21017625, 0.23734492, 0.28466557,\n",
       "        0.31458973, 0.23911683]),\n",
       " array([ 6329.56148222,  6347.55159965,  6339.53758782,  6104.48178636,\n",
       "         5966.36378861,  5719.40729499,  5712.3838591 ,  5594.89984592,\n",
       "         4851.71897906,  4099.58097071,  2469.06566866,  2526.82063983,\n",
       "         5228.62158002,  6510.88512667,  9126.05378112, 11154.19859146,\n",
       "         8020.19063101]),\n",
       " array([ 9006.52014461,  9023.54211012,  9016.45760721,  9017.71460612,\n",
       "         9144.30414309,  9180.23190909,  9452.82799994,  9625.57145544,\n",
       "        10389.39060867, 12376.74671387, 14020.14407861, 18967.25067576,\n",
       "        24877.31941279, 27432.16576138, 32058.86034556, 35456.33447617,\n",
       "        33540.88776429]),\n",
       " array([ 2676.9586624 ,  2675.99051047,  2676.9200194 ,  2913.23281976,\n",
       "         3177.94035448,  3460.8246141 ,  3740.44414084,  4030.67160952,\n",
       "         5537.67162962,  8277.16574316, 11551.07840996, 16440.43003593,\n",
       "        19648.69783277, 20921.28063471, 22932.80656444, 24302.13588471,\n",
       "        25520.69713328]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a11, a22, (Qin1_adj-Qout2_adj)/Qin1_adj, Qin1_adj-Qout2_adj, Qin1_adj, Qout2_adj\n",
    "#(Qin2+Qout2)/2, Qin1, Qout1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = xr.open_dataset('/home/1959/Parameters/FjordModeling/4_wTide_minhs.nc')\n",
    "file2 = xr.open_dataset('/home/1959/Parameters/FjordModeling/4_sTide_minhs.nc')\n",
    "\n",
    "n = -1\n",
    "a11 = np.concatenate([file1.alpha11.data, file2.alpha11.data[:]])\n",
    "a22 = np.concatenate([file1.alpha22.data, file2.alpha22.data[:]])\n",
    "\n",
    "Qin1 = np.concatenate([file1.Qin1.data, file2.Qin1.data[:]])\n",
    "Qin1_adj = np.concatenate([file1.Qin1_adj.data, file2.Qin1_adj.data[:]])\n",
    "\n",
    "Qin2 = np.concatenate([file1.Qin2.data, file2.Qin2.data[:]])\n",
    "Qin2_adj = np.concatenate([file1.Qin2_adj.data, file2.Qin2_adj.data[:]])\n",
    "\n",
    "Qout1 = np.concatenate([file1.Qout1.data, file2.Qout1.data[:]])\n",
    "Qout1_adj = np.concatenate([file1.Qout1_adj.data, file2.Qout1_adj.data[:]])\n",
    "\n",
    "Qout2 = np.concatenate([file1.Qout2.data, file2.Qout2.data[:]])\n",
    "Qout2_adj = np.concatenate([file1.Qout2_adj.data, file2.Qout2_adj.data[:]])\n",
    "\n",
    "Ts_in = np.concatenate([file1.Ts_in.data, file2.Ts_in.data[:]])\n",
    "Ts = np.concatenate([file1.Ts.data, file2.Ts.data[:]])\n",
    "Tf = np.concatenate([file1.Tf.data, file2.Tf.data[:]])\n",
    "\n",
    "Qsm = np.concatenate([file1.Qsm.data, file2.Qsm.data[:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca572eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Qin1_adj+Qout1_adj)/2, (Qin2+Qout2)/2, (Qin1-Qout2), (Qin1-Qout2)/Qin1*100\n",
    "a11, a22, (Qin1_adj-Qout2_adj)/Qin1_adj, Ts_in, Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c89c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_ds = xr.Dataset(\n",
    "    data_vars={'U0' : np.array([1e-4, 2e-4, 3e-4, 1e-3, 2e-3]),\n",
    "    'alpha11' : (Qin1_adj-Qout2_adj)/Qin1_adj,\n",
    "    'alpha22' : a22,\n",
    "    'Qin1' : Qin1_adj,\n",
    "    'Qin2' : Qin2_adj,\n",
    "    'Qout1' : Qout1_adj,\n",
    "    'Qout2' : Qout2_adj,\n",
    "    'Ts_in' : Ts_in,\n",
    "    'Tf' : Tf,\n",
    "    'Ts_model' : Ts})\n",
    "\n",
    "outdir = \"/home/1959/Parameters/FjordModeling/Eq4/\"\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "parameter_ds.to_netcdf(outdir + '4-Tide.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db8570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts/Ts_in*100, Qsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e154b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file3 = xr.open_dataset('/home/1959/Parameters/FjordModeling/1_BaseCase.nc')\n",
    "a11b = file3.alpha11.data\n",
    "a22b = file3.alpha22.data\n",
    "Qin1b = file3.Qin1.data\n",
    "Qin2b = file3.Qin2.data\n",
    "Qout1b = file3.Qout1.data\n",
    "Qout2b = file3.Qout2.data\n",
    "Qsmb = file3.Qsm.data\n",
    "Tsb = file3.Ts.data\n",
    "Ts_inb = file3.Ts_in.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79935959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.71530895, 0.56250147, 0.42047409, 0.29042472, 0.17951959,\n",
       "        0.01136236]),\n",
       " array([ 0.04242288,  0.00787062, -0.01761308, -0.04125368, -0.02628035,\n",
       "         0.00991505]),\n",
       " array([2548.01896578, 3872.47116847, 4963.0527807 , 5844.6496557 ,\n",
       "        6406.33548218, 7160.25633201]),\n",
       " array([9024.81065508, 9069.39780591, 8925.31153739, 8745.61446087,\n",
       "        8160.76748157, 7358.33371601]),\n",
       " array([2672.11268784, 3997.34417539, 5087.22163861, 5969.71802319,\n",
       "        6530.65636717, 7343.89914516]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a11b, a22b, (Qin2b+Qout2b)/2, file3.Qin1_adj.data, file3.Qout2_adj.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee53c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_path = '/work/oceans/wbao/MITgcm_results/iceplume/6_Tide_minhs'\n",
    "case_id = 5\n",
    "State0 = xr.open_dataset(case_path + '/state_' + str(format(case_id,'03d')) + '.nc')\n",
    "State = State0.isel(T=~State0.get_index(\"T\").duplicated())\n",
    "state = State.isel(X=range(260), Xp1=range(261), Y=range(35,45), T=range(1,len(State.T)))\n",
    "eta = state.Eta.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b96b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta.max(), eta.min(), eta.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f177ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gsw\n",
    "def ambient_strat(datapath, case_id):\n",
    "    \n",
    "    State01 = xr.open_dataset(datapath + '/state_' + str(format(case_id,'03d')) + '.nc')    \n",
    "    State = State01.isel(T=~State01.get_index(\"T\").duplicated())\n",
    "    state = State.isel(X=range(260), Xp1=range(261), Y=range(35,45), Yp1=range(35,45), T=range(89,len(State.T)))\n",
    "    \n",
    "    xidx = 2 # Glacier front index\n",
    "    \n",
    "    # Potential temp\n",
    "    T0 = state.Temp.data[:,:,:,xidx].mean(axis=(0,2))\n",
    "    \n",
    "    # Salinity\n",
    "    S0 = state.S.data[:,:,:,xidx].mean(axis=(0,2))\n",
    "    \n",
    "    depth = state.Z.data  \n",
    "    # Pressure\n",
    "    pres = gsw.p_from_z(depth, 55)\n",
    "\n",
    "    N2, Pmid = gsw.Nsquared(S0,T0,pres,55)\n",
    "    \n",
    "    return N2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9cf6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '/work/oceans/wbao/MITgcm_results/iceplume/weak_Tide_minhs'\n",
    "path2 = '/work/oceans/wbao/MITgcm_results/iceplume/6_Tide_minhs'\n",
    "path3 = '/work/oceans/wbao/MITgcm_results/iceplume/6_sTide_minhs'\n",
    "case1 = np.arange(1,4)\n",
    "case2 = np.arange(1,6)\n",
    "case3 = np.array([1,2,3,5,6,7,8,9,10])\n",
    "strat1 = np.empty(len(case1))\n",
    "strat2 = np.empty(len(case2))\n",
    "strat3 = np.empty(len(case3))\n",
    "\n",
    "for i in range(len(case1)):\n",
    "    strat1[i] = ambient_strat(path1, case1[i])\n",
    "\n",
    "for i in range(len(case2)):\n",
    "    strat2[i] = ambient_strat(path2, case2[i])\n",
    "\n",
    "for i in range(len(case3)):\n",
    "    strat3[i] = ambient_strat(path3, case3[i])\n",
    "\n",
    "tide_strat = np.concatenate([strat1, strat2, strat3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a9c2248",
   "metadata": {},
   "outputs": [],
   "source": [
    "path4 = '/work/oceans/wbao/MITgcm_results/iceplume/1_BaseCase'\n",
    "tide0_strat = ambient_strat(path4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fcf6102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.99697488e-05, 6.99685338e-05, 6.99712474e-05, 6.99737120e-05,\n",
       "        6.99724415e-05, 6.99992843e-05, 7.00097469e-05, 7.00284034e-05,\n",
       "        6.94419161e-05, 6.69205224e-05, 6.30316177e-05, 5.81249774e-05,\n",
       "        5.54740035e-05, 5.14967310e-05, 4.82219234e-05, 4.56854056e-05,\n",
       "        4.44674893e-05]),\n",
       " 6.997267818520045e-05)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tide_strat, tide0_strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5678d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
